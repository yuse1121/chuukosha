import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
import joblib

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆä»®æƒ³ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼‰
np.random.seed(42)
data_size = 1000

# 1. ãƒ¡ãƒ¼ã‚«ãƒ¼ãƒªã‚¹ãƒˆã¨å‡ºç¾ç¢ºç‡ã®å®šç¾©
MAKER_LIST = ['ãƒˆãƒ¨ã‚¿', 'ãƒ›ãƒ³ãƒ€', 'æ—¥ç”£', 'BMW', 'ãƒãƒ„ãƒ€', 'ã‚¹ãƒãƒ«', 'ãƒ¡ãƒ«ã‚»ãƒ‡ã‚¹', 'ã‚¢ã‚¦ãƒ‡ã‚£']
PROBABILITIES = [0.2, 0.15, 0.1, 0.1, 0.05, 0.05, 0.2, 0.15] # åˆè¨ˆã¯ 1.0

# ç‰¹å¾´é‡ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰ã®ãƒªã‚¹ãƒˆ
data = {
    'èµ°è¡Œè·é›¢_km': np.random.randint(10000, 150000, data_size),
    'å¹´å¼': np.random.randint(2015, 2025, data_size),
    'ãƒ¡ãƒ¼ã‚«ãƒ¼': np.random.choice(MAKER_LIST, data_size, p=PROBABILITIES), 
    'çŠ¶æ…‹_è©•ä¾¡': np.random.randint(1, 6, data_size), # 5ãŒæœ€é«˜
}
df = pd.DataFrame(data)

# ä¾¡æ ¼ï¼ˆç›®çš„å¤‰æ•°ï¼‰ã®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
df['ä¾¡æ ¼'] = (
    2500000  # åŸºæœ¬ä¾¡æ ¼
    - (df['èµ°è¡Œè·é›¢_km'] * 8) 
    - ((2025 - df['å¹´å¼']) * 150000)
    + df['çŠ¶æ…‹_è©•ä¾¡'] * 50000
    + df['ãƒ¡ãƒ¼ã‚«ãƒ¼'].apply(lambda x: 
        500000 if x in ['BMW', 'ãƒ¡ãƒ«ã‚»ãƒ‡ã‚¹', 'ã‚¢ã‚¦ãƒ‡ã‚£'] else 
        150000 if x == 'ãƒˆãƒ¨ã‚¿' else
        50000 if x in ['ãƒ›ãƒ³ãƒ€', 'ã‚¹ãƒãƒ«'] else 
        0) 
    + np.random.randn(data_size) * 100000 # ãƒã‚¤ã‚º
).clip(lower=100000) 

# ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®è¨­å®š
X = df[['èµ°è¡Œè·é›¢_km', 'å¹´å¼', 'ãƒ¡ãƒ¼ã‚«ãƒ¼', 'çŠ¶æ…‹_è©•ä¾¡']] 
y = df['ä¾¡æ ¼']

# å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½œæˆ
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), ['ãƒ¡ãƒ¼ã‚«ãƒ¼'])
    ],
    remainder='passthrough' # ãƒ¡ãƒ¼ã‚«ãƒ¼ä»¥å¤–ã®åˆ—ã‚’ãã®ã¾ã¾é€šéã•ã›ã‚‹
)

# ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½œæˆï¼ˆRandomForestRegressorã‚’ä½¿ç”¨ï¼‰
model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])

# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
model_pipeline.fit(X, y)

# ğŸ’¡ NEW: ç‰¹å¾´é‡ã®åå‰ã¨é‡è¦åº¦ã‚’å–å¾—
# ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã¨ã€å‰å‡¦ç†å¾Œã®ç‰¹å¾´é‡ã®åå‰ã‚’çµåˆ
feature_names = model_pipeline['preprocessor'].get_feature_names_out()
importances = model_pipeline['regressor'].feature_importances_
feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})


# ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ã‚’ joblib å½¢å¼ã§ä¿å­˜
joblib.dump(model_pipeline, 'car_price_predictor_model.joblib')
joblib.dump(feature_importance_df, 'feature_importance.joblib') # NEW FILE
print("ãƒ¢ãƒ‡ãƒ« 'car_price_predictor_model.joblib' ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
print("ç‰¹å¾´é‡é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ 'feature_importance.joblib' ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")